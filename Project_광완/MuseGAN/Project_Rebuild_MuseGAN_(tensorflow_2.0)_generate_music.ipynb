{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_Rebuild_MuseGAN_(tensorflow_2.0)_generate_music.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPU0npvSp0VJkTFmnMr3Yu5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoBkJADQC3Rg","executionInfo":{"status":"ok","timestamp":1618453556451,"user_tz":-540,"elapsed":716,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}},"outputId":"825c6d2f-8db8-46b3-db33-5c837296d94b"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Apr 15 02:25:56 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jek1i7USHgMk","executionInfo":{"status":"ok","timestamp":1618453574596,"user_tz":-540,"elapsed":18849,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}},"outputId":"65607c09-b2fb-465a-f3fa-c0c868a6c228"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/MuseGAN"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/MuseGAN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IIf2Xun6dMG","executionInfo":{"status":"ok","timestamp":1618453576098,"user_tz":-540,"elapsed":20344,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.initializers import RandomNormal"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"bea2GXUXEOY6","executionInfo":{"status":"ok","timestamp":1618453576483,"user_tz":-540,"elapsed":20724,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}}},"source":["# data_ints = np.load('./data/lift_every_voice_amplified.npy')\n","data_ints = np.load('./data/Jsb16thSeparated.npy')\n","\n","max_note = 83\n","\n","where_are_NaNs = np.isnan(data_ints)\n","\n","data_ints[where_are_NaNs] = max_note + 1\n","max_note = max_note + 1\n","\n","data_ints = data_ints.astype(int)\n","num_classes = max_note + 1\n","\n","data_binary = np.eye(num_classes)[data_ints]\n","data_binary[data_binary == 0] = -1\n","data_binary = np.delete(data_binary, max_note, -1)\n","\n","data_binary = data_binary.transpose([0,1,2, 4,3])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSy4Cx2zVWqG","executionInfo":{"status":"ok","timestamp":1618453576485,"user_tz":-540,"elapsed":20722,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}},"outputId":"d664acb7-80b3-4ab5-9823-1177f3670486"},"source":["data_binary.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(229, 2, 16, 84, 4)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_uH156QCpmX","executionInfo":{"status":"ok","timestamp":1618453576486,"user_tz":-540,"elapsed":20716,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}},"outputId":"133fbb27-5cc4-40c4-b601-054b7d3948f9"},"source":["IMG_SHAPE = data_binary.shape[1:]\n","BATCH_SIZE = 64\n","WEIGHT_INIT = RandomNormal(mean=0., stddev=0.02)\n","\n","# Size of the noise vector\n","noise_dim = 32\n","\n","train_images = data_binary\n","\n","print(f\"Number of examples: {len(train_images)}\")\n","print(f\"Shape of the images in the dataset: {train_images.shape[1:]}\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Number of examples: 229\n","Shape of the images in the dataset: (2, 16, 84, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFoThjS96yC7","executionInfo":{"status":"ok","timestamp":1618453581812,"user_tz":-540,"elapsed":26035,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}},"outputId":"1bb6b4ed-abe4-4c64-a131-633888597e6c"},"source":["def get_discriminator_model():\n","\n","  critic_input = layers.Input(shape = IMG_SHAPE, name = 'discriminator_input')\n","\n","  x = layers.ZeroPadding3D((1, 1, 1))(critic_input)\n","\n","  x = layers.Conv3D(filters = 128,\n","                    kernel_size = (2, 1, 1),\n","                    strides = (1, 1, 1),\n","                    kernel_initializer = WEIGHT_INIT,\n","                    padding = 'valid')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  x = layers.Conv3D(filters = 128,\n","                    kernel_size = (train_images.shape[1] - 1, 1, 1),\n","                    strides = (1, 1, 1),\n","                    kernel_initializer = WEIGHT_INIT,\n","                    padding = 'valid')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","\n","  x = layers.Conv3D(filters = 128,\n","                    kernel_size = (1, 1, 12),\n","                    strides = (1, 1, 12),\n","                    kernel_initializer = WEIGHT_INIT,\n","                    padding = 'same')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  x = layers.Conv3D(filters = 128,\n","                    kernel_size = (1, 1, 7),\n","                    strides = (1, 1, 7),\n","                    kernel_initializer = WEIGHT_INIT,\n","                    padding = 'same')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  x = layers.Conv3D(filters = 128,\n","                    kernel_size = (1, 2, 1),\n","                    strides = (1, 2, 1),\n","                    kernel_initializer = WEIGHT_INIT,\n","                    padding = 'same')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  x = layers.Conv3D(filters = 128,\n","                       kernel_size = (1, 2, 1),\n","                       strides = (1, 2, 1),\n","                       kernel_initializer = WEIGHT_INIT,\n","                       padding = 'same')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  x = layers.Conv3D(filters = 128,\n","                    kernel_size = (1, 4, 1),\n","                    strides = (1, 2, 1),\n","                    kernel_initializer = WEIGHT_INIT,\n","                    padding = 'same')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  x = layers.Conv3D(filters = 128,\n","                    kernel_size = (1, 3, 1),\n","                    strides = (1, 2, 1),\n","                    kernel_initializer = WEIGHT_INIT,\n","                    padding = 'same')(x)\n","  x = layers.LeakyReLU()(x)\n","\n","\n","  x = layers.Flatten()(x)\n","\n","  x = layers.Dense(1024, kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.LeakyReLU()(x)\n","  critic_output = layers.Dense(1, activation = None, kernel_initializer = WEIGHT_INIT)(x)\n","\n","  d_model = keras.models.Model(critic_input, critic_output, name  = 'discriminator')\n","  return d_model\n","\n","d_model = get_discriminator_model()\n","d_model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","discriminator_input (InputLa [(None, 2, 16, 84, 4)]    0         \n","_________________________________________________________________\n","zero_padding3d (ZeroPadding3 (None, 4, 18, 86, 4)      0         \n","_________________________________________________________________\n","conv3d (Conv3D)              (None, 3, 18, 86, 128)    1152      \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 3, 18, 86, 128)    0         \n","_________________________________________________________________\n","conv3d_1 (Conv3D)            (None, 3, 18, 86, 128)    16512     \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 3, 18, 86, 128)    0         \n","_________________________________________________________________\n","conv3d_2 (Conv3D)            (None, 3, 18, 8, 128)     196736    \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 3, 18, 8, 128)     0         \n","_________________________________________________________________\n","conv3d_3 (Conv3D)            (None, 3, 18, 2, 128)     114816    \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 3, 18, 2, 128)     0         \n","_________________________________________________________________\n","conv3d_4 (Conv3D)            (None, 3, 9, 2, 128)      32896     \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 3, 9, 2, 128)      0         \n","_________________________________________________________________\n","conv3d_5 (Conv3D)            (None, 3, 5, 2, 128)      32896     \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 3, 5, 2, 128)      0         \n","_________________________________________________________________\n","conv3d_6 (Conv3D)            (None, 3, 3, 2, 128)      65664     \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 3, 3, 2, 128)      0         \n","_________________________________________________________________\n","conv3d_7 (Conv3D)            (None, 3, 2, 2, 128)      49280     \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 3, 2, 2, 128)      0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1536)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              1573888   \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 1025      \n","=================================================================\n","Total params: 2,084,865\n","Trainable params: 2,084,865\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqG4MQ_m61Ad","executionInfo":{"status":"ok","timestamp":1618453583653,"user_tz":-540,"elapsed":27870,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}},"outputId":"0b18764f-4fbc-45e8-8e38-38709e689193"},"source":["def temporal_network():\n","\n","  input_layer = layers.Input(shape = (noise_dim, ), name = 'temporal_input')\n","\n","  x = layers.Reshape([1, 1, noise_dim])(input_layer)\n","\n","  x = layers.Conv2DTranspose(filters = 1024,\n","                             kernel_size = (2, 1),\n","                             padding = 'valid',\n","                             strides = (1, 1),\n","                             kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.BatchNormalization(momentum = 0.9)(x)\n","  x = layers.Activation('relu')(x)\n","\n","  x = layers.Conv2DTranspose(filters = noise_dim,\n","                             kernel_size = (train_images.shape[1] - 1, 1),\n","                             padding = 'valid',\n","                             strides = (1, 1),\n","                             kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.BatchNormalization(momentum = 0.9)(x)\n","  x = layers.Activation('relu')(x)\n","\n","  output_layer = layers.Reshape([train_images.shape[1], noise_dim])(x)\n","\n","  return keras.models.Model(input_layer, output_layer)\n","\n","\n","def BarGenerator():\n","  input_layer = layers.Input(shape = (noise_dim * 4, ), name = 'bar_generator_input')\n","\n","  x = layers.Dense(1024)(input_layer)\n","  x = layers.BatchNormalization(momentum = 0.9)(x)\n","  x = layers.Activation('relu')(x)\n","\n","  x = layers.Reshape([2, 1, 512])(x)\n","\n","  x = layers.Conv2DTranspose(filters = 512,\n","                             kernel_size = (2, 1),\n","                             padding = 'same',\n","                             strides = (2, 1),\n","                             kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.BatchNormalization(momentum = 0.9)(x)\n","  x = layers.Activation('relu')(x)\n","\n","  x = layers.Conv2DTranspose(filters = 256,\n","                             kernel_size = (2, 1),\n","                             padding = 'same',\n","                             strides = (2, 1),\n","                             kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.BatchNormalization(momentum = 0.9)(x)\n","  x = layers.Activation('relu')(x)\n","\n","  x = layers.Conv2DTranspose(filters = 256,\n","                             kernel_size = (2, 1),\n","                             padding = 'same',\n","                             strides = (2, 1),\n","                             kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.BatchNormalization(momentum = 0.9)(x)\n","  x = layers.Activation('relu')(x)\n","\n","  x = layers.Conv2DTranspose(filters = 256,\n","                             kernel_size = (1, 7),\n","                             padding = 'same',\n","                             strides = (1, 7),\n","                             kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.BatchNormalization(momentum = 0.9)(x)\n","  x = layers.Activation('relu')(x)\n","\n","  x = layers.Conv2DTranspose(filters = 1,\n","                             kernel_size = (1, 12),\n","                             padding = 'same',\n","                             strides = (1, 12),\n","                             kernel_initializer = WEIGHT_INIT)(x)\n","  x = layers.Activation('tanh')(x)\n","\n","  output_layer = layers.Reshape([1, train_images.shape[2], train_images.shape[3], 1])(x)\n","\n","  return keras.models.Model(input_layer, output_layer)\n","\n","\n","def get_generator_model():\n","\n","  input = layers.Input(shape = (noise_dim, ), name = 'noise_input')\n","\n","  chords_input = layers.Lambda(lambda x: x[:, :])(input)\n","  style_input = layers.Lambda(lambda x: x[:, :])(input)\n","  melody_input = layers.Lambda(lambda x: x[:, :])(input)\n","  groove_input = layers.Lambda(lambda x: x[:, :])(input)\n","\n","\n","\n","\n","  # 화음\n","  # chords_input = layers.Input(shape = (noise_dim, ), name = 'chords_input')\n","  chords_temporal_network = temporal_network()\n","  chords_over_time = chords_temporal_network(chords_input)\n","  # 스타일\n","  # style_input = layers.Input(shape = (noise_dim, ), name = 'style_input')\n","  # 멜로디\n","  # melody_input = layers.Input(shape = (train_images.shape[4], noise_dim), name = 'melody_input')\n","  melody_over_time = [None] * train_images.shape[4]\n","  melody_temporal_network = [None] * train_images.shape[4]\n","  for track in range(train_images.shape[4]):   # 악기 갯수(train_images.shape[4]) 별로 생성\n","    melody_temporal_network[track] = temporal_network()\n","    melody_track = layers.Lambda(lambda x: x[:, :])(melody_input)\n","    melody_over_time[track] = melody_temporal_network[track](melody_track)\n","  # 리듬\n","  # groove_input = layers.Input(shape = (train_images.shape[4], noise_dim), name = 'groove_input')\n","\n","  # 트랙마다 마디 생성자를 만듭니다.\n","  barGen = [None] * train_images.shape[4]\n","  for track in range(train_images.shape[4]):\n","    barGen[track] = BarGenerator()\n","  # 트랙과 마디마다 출력을 생성합니다.\n","  bars_output = [None] * train_images.shape[1]\n","  for bar in range(train_images.shape[1]):\n","    track_output = [None] * train_images.shape[4]\n","\n","    c = layers.Lambda(lambda x: x[:, bar, :],\n","                      name = 'chords_input_bar_' + str(bar))(chords_over_time)\n","    s = style_input\n","\n","    for track in range(train_images.shape[4]):\n","      m = layers.Lambda(lambda x: x[:, bar, :])(melody_over_time[track])\n","      g = layers.Lambda(lambda x: x[:, :])(groove_input)\n","\n","      z_input = layers.Concatenate(axis = 1,\n","                                   name = 'total_input_bar_{}_track_{}'.format(bar, track))([c, s, m, g])\n","      track_output[track] = barGen[track](z_input)\n","\n","    bars_output[bar] = layers.Concatenate(axis = -1)(track_output)\n","\n","  generator_output = layers.Concatenate(axis = 1, name = 'concat_bars')(bars_output)\n","\n","  g_model = keras.models.Model(input, generator_output)\n","\n","  return g_model\n","\n","\n","g_model = get_generator_model()\n","g_model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"model_9\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","noise_input (InputLayer)        [(None, 32)]         0                                            \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 32)           0           noise_input[0][0]                \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 32)           0           noise_input[0][0]                \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 32)           0           lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 32)           0           lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 32)           0           lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 32)           0           lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","model (Functional)              (None, 2, 32)        103584      lambda[0][0]                     \n","__________________________________________________________________________________________________\n","model_1 (Functional)            (None, 2, 32)        103584      lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 32)           0           noise_input[0][0]                \n","__________________________________________________________________________________________________\n","model_2 (Functional)            (None, 2, 32)        103584      lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","model_3 (Functional)            (None, 2, 32)        103584      lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","model_4 (Functional)            (None, 2, 32)        103584      lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","chords_input_bar_0 (Lambda)     (None, 32)           0           model[0][0]                      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 32)           0           noise_input[0][0]                \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 32)           0           model_1[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 32)           0           model_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 32)           0           model_3[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 32)           0           model_4[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","chords_input_bar_1 (Lambda)     (None, 32)           0           model[0][0]                      \n","__________________________________________________________________________________________________\n","lambda_16 (Lambda)              (None, 32)           0           model_1[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_17 (Lambda)              (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_18 (Lambda)              (None, 32)           0           model_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_19 (Lambda)              (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_20 (Lambda)              (None, 32)           0           model_3[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_21 (Lambda)              (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_22 (Lambda)              (None, 32)           0           model_4[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_23 (Lambda)              (None, 32)           0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","total_input_bar_0_track_0 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_8[0][0]                   \n","                                                                 lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","total_input_bar_0_track_1 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_10[0][0]                  \n","                                                                 lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","total_input_bar_0_track_2 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_12[0][0]                  \n","                                                                 lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","total_input_bar_0_track_3 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_14[0][0]                  \n","                                                                 lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","total_input_bar_1_track_0 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_16[0][0]                  \n","                                                                 lambda_17[0][0]                  \n","__________________________________________________________________________________________________\n","total_input_bar_1_track_1 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_18[0][0]                  \n","                                                                 lambda_19[0][0]                  \n","__________________________________________________________________________________________________\n","total_input_bar_1_track_2 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_20[0][0]                  \n","                                                                 lambda_21[0][0]                  \n","__________________________________________________________________________________________________\n","total_input_bar_1_track_3 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n","                                                                 lambda_1[0][0]                   \n","                                                                 lambda_22[0][0]                  \n","                                                                 lambda_23[0][0]                  \n","__________________________________________________________________________________________________\n","model_5 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_0[0][0]  \n","                                                                 total_input_bar_1_track_0[0][0]  \n","__________________________________________________________________________________________________\n","model_6 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_1[0][0]  \n","                                                                 total_input_bar_1_track_1[0][0]  \n","__________________________________________________________________________________________________\n","model_7 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_2[0][0]  \n","                                                                 total_input_bar_1_track_2[0][0]  \n","__________________________________________________________________________________________________\n","model_8 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_3[0][0]  \n","                                                                 total_input_bar_1_track_3[0][0]  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 1, 16, 84, 4) 0           model_5[0][0]                    \n","                                                                 model_6[0][0]                    \n","                                                                 model_7[0][0]                    \n","                                                                 model_8[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 1, 16, 84, 4) 0           model_5[1][0]                    \n","                                                                 model_6[1][0]                    \n","                                                                 model_7[1][0]                    \n","                                                                 model_8[1][0]                    \n","__________________________________________________________________________________________________\n","concat_bars (Concatenate)       (None, 2, 16, 84, 4) 0           concatenate[0][0]                \n","                                                                 concatenate_1[0][0]              \n","==================================================================================================\n","Total params: 6,605,604\n","Trainable params: 6,576,612\n","Non-trainable params: 28,992\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eHIS5E2E61mh","executionInfo":{"status":"ok","timestamp":1618453583654,"user_tz":-540,"elapsed":27864,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}}},"source":["class WGAN(keras.Model):\n","    def __init__(\n","        self,\n","        discriminator,\n","        generator,\n","        latent_dim,\n","        tracks_dim,\n","        discriminator_extra_steps=3,\n","        gp_weight=10.0,\n","    ):\n","        super(WGAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.tracks_dim = tracks_dim\n","        self.d_steps = discriminator_extra_steps\n","        self.gp_weight = gp_weight\n","\n","    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n","        super(WGAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.d_loss_fn = d_loss_fn\n","        self.g_loss_fn = g_loss_fn\n","\n","    def gradient_penalty(self, batch_size, real_images, fake_images):\n","        \"\"\" Calculates the gradient penalty.\n","\n","        This loss is calculated on an interpolated image\n","        and added to the discriminator loss.\n","        \"\"\"\n","        # Get the interpolated image\n","        alpha = tf.random.normal([batch_size, 1, 1, 1, 1], 0.0, 1.0)\n","        diff = fake_images - real_images\n","        interpolated = real_images + alpha * diff\n","\n","        with tf.GradientTape() as gp_tape:\n","            gp_tape.watch(interpolated)\n","            # 1. Get the discriminator output for this interpolated image.\n","            pred = self.discriminator(interpolated, training=True)\n","\n","        # 2. Calculate the gradients w.r.t to this interpolated image.\n","        grads = gp_tape.gradient(pred, [interpolated])[0]\n","        # 3. Calculate the norm of the gradients.\n","        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","        gp = tf.reduce_mean((norm - 1.0) ** 2)\n","        return gp\n","\n","    def train_step(self, real_images):\n","        if isinstance(real_images, tuple):\n","            real_images = real_images[0]\n","\n","        # Get the batch size\n","        batch_size = tf.shape(real_images)[0]\n","\n","\n","        # For each batch, we are going to perform the\n","        # following steps as laid out in the original paper:\n","        # 1. Train the generator and get the generator loss\n","        # 2. Train the discriminator and get the discriminator loss\n","        # 3. Calculate the gradient penalty\n","        # 4. Multiply this gradient penalty with a constant weight factor\n","        # 5. Add the gradient penalty to the discriminator loss\n","        # 6. Return the generator and discriminator losses as a loss dictionary\n","\n","        # Train the discriminator first. The original paper recommends training\n","        # the discriminator for `x` more steps (typically 5) as compared to\n","        # one step of the generator. Here we will train it for 3 extra steps\n","        # as compared to 5 to reduce the training time.\n","        for i in range(self.d_steps):\n","            global B\n","            B = i\n","\n","            # Get the latent vector\n","            random_latent_vectors = tf.random.normal(\n","                shape=(batch_size, self.latent_dim)\n","            )\n","\n","            with tf.GradientTape() as tape:\n","                # Generate fake images from the latent vector\n","                fake_images = self.generator(random_latent_vectors, training=True)\n","                # Get the logits for the fake images\n","                fake_logits = self.discriminator(fake_images, training=True)\n","                # Get the logits for the real images\n","                real_logits = self.discriminator(real_images, training=True)\n","\n","                # Calculate the discriminator loss using the fake and real image logits\n","                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n","                # Calculate the gradient penalty\n","                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n","                # Add the gradient penalty to the original discriminator loss\n","                d_loss = d_cost + gp * self.gp_weight\n","\n","\n","            # Get the gradients w.r.t the discriminator loss\n","            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n","            # Update the weights of the discriminator using the discriminator optimizer\n","            self.d_optimizer.apply_gradients(\n","                zip(d_gradient, self.discriminator.trainable_variables)\n","            )\n","\n","\n","        # Train the generator\n","        # Get the latent vector\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        with tf.GradientTape() as tape:\n","            # Generate fake images using the generator\n","            generated_images = self.generator(random_latent_vectors, training=True)\n","            # Get the discriminator logits for fake images\n","            gen_img_logits = self.discriminator(generated_images, training=True)\n","            # Calculate the generator loss\n","            g_loss = self.g_loss_fn(gen_img_logits)\n","\n","        # Get the gradients w.r.t the generator loss\n","        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n","        # Update the weights of the generator using the generator optimizer\n","        self.g_optimizer.apply_gradients(\n","            zip(gen_gradient, self.generator.trainable_variables)\n","        )\n","        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"BuCWF94x64yJ","executionInfo":{"status":"ok","timestamp":1618453584805,"user_tz":-540,"elapsed":29008,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}}},"source":["from music21 import *\n","\n","class GANMonitor(keras.callbacks.Callback):\n","    def __init__(self, latent_dim=128):\n","        self.latent_dim = latent_dim\n","    def on_epoch_end(self, epoch, logs=None):\n","      if epoch % 100 == 0:\n","        random_latent_vectors = tf.random.normal(shape=(1, self.latent_dim))\n","        output = self.model.generator(random_latent_vectors)\n","        for score_num in range(len(output)):\n","          max_pitches = np.argmax(output, axis = 3)\n","          midi_note_score = max_pitches[score_num].reshape([train_images.shape[1] * train_images.shape[2], train_images.shape[4]])\n","          parts = stream.Score()\n","          parts.append(tempo.MetronomeMark(number=66))\n","          for i in range(train_images.shape[4]):\n","            last_x = int(midi_note_score[:, i][0])\n","            s = stream.Part()\n","            dur = 0\n","            for idx, x in enumerate(midi_note_score[:, i]):\n","              x = int(x)\n","              if (x != last_x or idx % 4 == 0) and idx > 0:\n","                n = note.Note(last_x)\n","                n.duration = duration.Duration(dur)\n","                s.append(n)\n","                dur = 0\n","              last_x = x\n","              dur = dur + 0.25\n","            n = note.Note(last_x)\n","            n.duration = duration.Duration(dur)\n","            s.append(n)            \n","            parts.append(s)\n","          parts.write('midi', fp = './output/sample_{}.midi'.format(epoch))\n","          self.model.generator.save_weights('./weights-g_{}.h5'.format(epoch))\n","          self.model.discriminator.save_weights('./weights-d_{}.h5'.format(epoch))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHA7TSR7679X","executionInfo":{"status":"ok","timestamp":1618453584806,"user_tz":-540,"elapsed":29004,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}}},"source":["# Instantiate the optimizer for both networks\n","# (learning_rate=0.0002, beta_1=0.5 are recommended)\n","generator_optimizer = keras.optimizers.Adam(\n","    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",")\n","discriminator_optimizer = keras.optimizers.Adam(\n","    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",")\n","\n","# Define the loss functions for the discriminator,\n","# which should be (fake_loss - real_loss).\n","# We will add the gradient penalty later to this loss function.\n","def discriminator_loss(real_img, fake_img):\n","    real_loss = tf.reduce_mean(real_img)\n","    fake_loss = tf.reduce_mean(fake_img)\n","    return fake_loss - real_loss\n","\n","\n","# Define the loss functions for the generator.\n","def generator_loss(fake_img):\n","    return -tf.reduce_mean(fake_img)\n","\n","\n","# Set the number of epochs for trainining.\n","epochs = 2000\n","\n","# Instantiate the customer `GANMonitor` Keras callback.\n","cbk = GANMonitor(latent_dim=noise_dim)\n","\n","# Instantiate the WGAN model.\n","wgan = WGAN(\n","    discriminator=d_model,\n","    generator=g_model,\n","    latent_dim=noise_dim,\n","    tracks_dim=train_images[4],\n","    discriminator_extra_steps=3,\n",")\n","\n","# Compile the WGAN model.\n","wgan.compile(\n","    d_optimizer=discriminator_optimizer,\n","    g_optimizer=generator_optimizer,\n","    g_loss_fn=generator_loss,\n","    d_loss_fn=discriminator_loss,\n",")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SzaFYkpUCdBh","executionInfo":{"status":"ok","timestamp":1618453634981,"user_tz":-540,"elapsed":79174,"user":{"displayName":"john woo","photoUrl":"","userId":"08981602208379271501"}},"outputId":"5420d2da-88a7-44b7-a050-549d14f75f2e"},"source":["g_model.load_weights('/content/drive/MyDrive/MuseGAN/weights-g_1900.h5', None)\n","\n","for m in range(50):\n","  random_latent_vectors = tf.random.normal(shape=(1, noise_dim))\n","  output = g_model(random_latent_vectors)\n","  for score_num in range(len(output)):\n","    max_pitches = np.argmax(output, axis = 3)\n","    midi_note_score = max_pitches[score_num].reshape([train_images.shape[1] * train_images.shape[2], train_images.shape[4]])\n","    parts = stream.Score()\n","    parts.append(tempo.MetronomeMark(number=66))\n","    for i in range(train_images.shape[4]):\n","      last_x = int(midi_note_score[:, i][0])\n","      s = stream.Part()\n","      dur = 0\n","      for idx, x in enumerate(midi_note_score[:, i]):\n","        x = int(x)\n","        if (x != last_x or idx % 4 == 0) and idx > 0:\n","          n = note.Note(last_x)\n","          n.duration = duration.Duration(dur)\n","          s.append(n)\n","          dur = 0\n","        last_x = x\n","        dur = dur + 0.25\n","      n = note.Note(last_x)\n","      n.duration = duration.Duration(dur)\n","      s.append(n)            \n","      parts.append(s)\n","    parts.write('midi', fp = './generate/sample_{}.midi'.format(m))\n","    print('./generate/sample_{}.midi'.format(m))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["./generate/sample_0.midi\n","./generate/sample_1.midi\n","./generate/sample_2.midi\n","./generate/sample_3.midi\n","./generate/sample_4.midi\n","./generate/sample_5.midi\n","./generate/sample_6.midi\n","./generate/sample_7.midi\n","./generate/sample_8.midi\n","./generate/sample_9.midi\n","./generate/sample_10.midi\n","./generate/sample_11.midi\n","./generate/sample_12.midi\n","./generate/sample_13.midi\n","./generate/sample_14.midi\n","./generate/sample_15.midi\n","./generate/sample_16.midi\n","./generate/sample_17.midi\n","./generate/sample_18.midi\n","./generate/sample_19.midi\n","./generate/sample_20.midi\n","./generate/sample_21.midi\n","./generate/sample_22.midi\n","./generate/sample_23.midi\n","./generate/sample_24.midi\n","./generate/sample_25.midi\n","./generate/sample_26.midi\n","./generate/sample_27.midi\n","./generate/sample_28.midi\n","./generate/sample_29.midi\n","./generate/sample_30.midi\n","./generate/sample_31.midi\n","./generate/sample_32.midi\n","./generate/sample_33.midi\n","./generate/sample_34.midi\n","./generate/sample_35.midi\n","./generate/sample_36.midi\n","./generate/sample_37.midi\n","./generate/sample_38.midi\n","./generate/sample_39.midi\n","./generate/sample_40.midi\n","./generate/sample_41.midi\n","./generate/sample_42.midi\n","./generate/sample_43.midi\n","./generate/sample_44.midi\n","./generate/sample_45.midi\n","./generate/sample_46.midi\n","./generate/sample_47.midi\n","./generate/sample_48.midi\n","./generate/sample_49.midi\n"],"name":"stdout"}]}]}