# Attention LSTM



**1. 데이터**

> 사용된 데이터는 프로젝트 평가만을 위해 제출되며, 깃허브에는 올리지 않을 예정입니다.
>
> 필요하신 분은 사이트 링크를 참고하세요.

데이터는 라흐마니노프 피아노 곡(사이트 링크http://www.piano-midi.de/rach.htm)을 사용했습니다.

클래식 곡의 원곡은 대부분 저작권이 소멸한 퍼블릭 도메인입니다.

클래식 데이터를 사용할 경우 주로 다음의 두 가지를 주의해야 합니다.

- 편곡된 경우 편곡 악보는 편곡자에게 그 권리가 있습니다.
- 원곡이라고 하더라도 피아니스트의 연주를 녹음한 경우 피아니스트에게 그 권리가 있습니다.

사용한 라흐마니노프 피아노 곡 데이터는 원곡의 미디 파일로, 미디 파일의 음악은 컴퓨터로 생성되어 연주자가 따로 존재하지 않습니다.

preprocessing/data/Rachmaninov 디렉터리에 원곡의 미디 파일이 존재하며, `Rachmaninov_00_preprocessing.ipynb`를 통해 전처리가 진행되었습니다.



**2. 전처리**

전처리에는 music21 패키지가 필요합니다. 이 패키지는 파이썬에서 미디 파일을 다룰 수 있도록 도와줍니다.

music21 패키지는 Attention LSTM을 통해 만든 곡을 미디 파일로 변환할 때도 필요합니다.



도움을 받은 사이트는 다음과 같습니다.

- Skuldur 깃허브(사이트 링크 https://github.com/Skuldur/Classical-Piano-Composer)



**3. 모델링**

Attention 메커니즘을 사용하면, RNN의 이전 타임스텝에 있는 은닉 상태의 가중치 합으로 문맥 벡터를 만듭니다. 즉, 음악의 더 긴 구간을 보고 다음 음표를 생성합니다.

해당 모델에서는 임베딩 크기 256와 LSTM layer 한 겹에 4096개씩 두 겹을 쌓았습니다.

총 파라미터 갯수는 219,298,194개입니다.



**4. 학습 및 곡 생성**

학습에 소요되는 시간은 한 에포크에 약 4분 정도 소요됩니다.

임베딩 크기는 100부터 2048까지 주어보았으나, 너무 큰 임베딩을 줄 필요는 없어보여 256으로 선택하였습니다.

LSTM layer 한 겹에 4096개씩 두 겹을 쌓은 이유는 512부터 4096까지 크기를 바꾸어 가며 에포크를 돌려본 결과, 레이어의 크기가 클수록 멜로디의 느낌이 더 다채로웠기 때문입니다.

며칠 학습을 시켜 loss 값을 0.23 수준까지 떨어뜨리니 점점 멜로디다운 멜로디가 생기기 시작했습니다. 원곡과 비교했을 경우 사람의 귀에는 새로운 곡이라는 느낌을 줍니다.

> [참고: loss 값을 낮추는 실험] 
>
> 두 마디 길이의 짧은 곡을 1965 에포크 학습해 loss 값이 5.9183e-04 밑으로 떨어진 모델을 만들었더니, LSTM 모델이 두 마디 곡을 완전히 외워버렸습니다. 'START' 값만 입력하였을 뿐인데, 원곡과 완전히 같은 음악을 생성했습니다. 그러므로, 원곡과 다른 곡을 만들기 위해서는 적당한 수준의 loss 값을 찾을 필요가 있습니다.